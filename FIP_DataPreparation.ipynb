{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood Impact Prediction (FIP) Data Preparation\n",
    "The description would be updated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, QuantileTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import fhv\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population\n",
    "\n",
    "The [Worldpop's 100m population data](https://www.worldpop.org/geodata/summary?id=5589) is downscaled to 30m by \"QGIS > Raster > Align Rasters\" to be consistent with inundation maps. In this process, the values are rescaled according to the resolution change, which is the option of the function.\n",
    "The total population in data was 158,150,540. This is rescaled to 159,670,593 (WorldBank, 2017).\n",
    "The final population raster has decuple values (10 times larger than original values) to avoid losing populated areas in integer (uint16) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inithial downscaled file is processed by QGIS\n",
    "if False:    # This is done already\n",
    "    with rasterio.open('./data/ppp_30m.tif') as src:    # This is done by QGIS\n",
    "        data = src.read(1)\n",
    "        data[data<0] = 0                     # Since the nodata value (-99999.0) is also rescaled\n",
    "        data = data/data.sum()*159679593     # Scale to WorldBank's population\n",
    "        data = np.round(data*10).astype(rasterio.uint16)\n",
    "        profile = src.profile.copy()\n",
    "        profile.update(\n",
    "            nodata=0,\n",
    "            dtype=rasterio.uint16,\n",
    "            compress='lzw')\n",
    "        out_fn = './data/bgd_ppp_2017_30m_decuple.tif'       # This file is the reference of all rasters\n",
    "        with rasterio.open(out_fn, 'w', **profile) as dst:\n",
    "            dst.write_band(1, data)\n",
    "        print('%s is saved.' % out_fn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a shapefile of the union to raster format\n",
    "Here we convert administrative boundary polygons (shapefile) to raster format. Specifically, we burn (convert) the ID number of unions in 30m spatial resolution. The shapefile of administrative boundaries is obtained from [OCHA-HDX](https://data.humdata.org/dataset/administrative-boundaries-of-bangladesh-as-of-2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# District\n",
    "shp_fn = './data/admin_boundary/bgd_admbnda_adm2_bbs_20180410.shp'\n",
    "gdf = gpd.read_file(shp_fn)\n",
    "shp_district = gdf[gdf.columns[[3,2,8,7,-1]]].sort_values('ADM2_PCODE').reset_index(drop=True)\n",
    "# Upazila\n",
    "shp_fn = './data/admin_boundary/bgd_admbnda_adm3_bbs_20180410.shp'\n",
    "gdf = gpd.read_file(shp_fn)\n",
    "shp_upazila = gdf[gdf.columns[[3,2,8,7,-1]]].sort_values('ADM3_PCODE').reset_index(drop=True)\n",
    "# Union\n",
    "shp_fn = './data/admin_boundary/bgd_admbnda_adm4_bbs_20180410.shp'\n",
    "gdf = gpd.read_file(shp_fn)\n",
    "shp_union = gdf[gdf.columns[[3,2,8,7,-1]]].sort_values('ADM4_PCODE').reset_index(drop=True)\n",
    "if False:\n",
    "    # Save template shapfiles\n",
    "    shp_district_fn = './data/adm_district.shp'\n",
    "    shp_district.to_file(shp_district_fn)\n",
    "    print('%s is saved..' % shp_district_fn)\n",
    "    shp_upazila_fn = './data/adm_upazila.shp'\n",
    "    shp_upazila.to_file(shp_upazila_fn)\n",
    "    print('%s is saved..' % shp_upazila_fn)\n",
    "    shp_union_fn = './data/adm_union.shp'\n",
    "    shp_union.to_file(shp_union_fn)\n",
    "    print('%s is saved..' % shp_union_fn)\n",
    "    \n",
    "# Convert a Union shapefile to raster\n",
    "rst_fn = './data/bgd_ppp_2017_30m_decuple.tif'\n",
    "out_fn = './data/unid_30m.tif'\n",
    "# fhv.ConvertShapeToRaster(shp_fn, rst_fn, out_fn, fieldname='ADM4_PCODE', out_dtype=rasterio.int32)\n",
    "\n",
    "# Validate the number of unions (validated)\n",
    "if False:\n",
    "    # Number of unions from shapefile (5160)\n",
    "    nUnion1 = np.unique(gpd.read_file(shp_fn)['ADM4_PCODE']).shape[0]\n",
    "    # Number of unions from raster (5160)\n",
    "    nUnion2 = np.unique(rasterio.open(out_fn).read(1)).shape[0] - 1\n",
    "    assert nUnion1 == nUnion2, 'the numbers of unions are different'\n",
    "\n",
    "# Union ID table\n",
    "uidList = shp_union['ADM4_PCODE'].astype(rasterio.int32)\n",
    "uidList.to_hdf('./data/uidlist.hdf', 'uidList')\n",
    "\n",
    "# List indexes of cells per union (This will make the aggregation easier)\n",
    "uidx_fn = './data/uidx.npz'\n",
    "if not os.path.exists(uidx_fn):\n",
    "    start_time = time.time()\n",
    "    idun = rasterio.open('./data/unid_30m.tif').read(1)                 # Union ID\n",
    "    uidx = []\n",
    "    for i,uid in uidList.iteritems():\n",
    "        uidx.append(np.ravel_multi_index(np.where(idun==uid), idun.shape))\n",
    "        print(i)\n",
    "    # Save to numpy file\n",
    "    np.savez_compressed('./data/uidx', uidx=uidx)\n",
    "    print('elapsed_time: %ds' % (time.time() - start_time))\n",
    "else:\n",
    "    uidx = np.load(uidx_fn, allow_pickle=True)['uidx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([289002963, 289020265, 289020266, ..., 296235663, 296252964,\n",
       "       296252965]),\n",
       "       array([289158434, 289175734, 289175735, ..., 293501692, 293501693,\n",
       "       293501694]),\n",
       "       array([280645977, 280645978, 280663269, ..., 288518854, 288536157,\n",
       "       288553460]),\n",
       "       ...,\n",
       "       array([109267435, 109284737, 109284738, ..., 113558612, 113558613,\n",
       "       113558614]),\n",
       "       array([112001234, 112001235, 112018536, ..., 114579453, 114579454,\n",
       "       114579455]),\n",
       "       array([111983892, 111983893, 111983894, ..., 113437383, 113437384,\n",
       "       113437385])], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uidx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inundated areas from Sentinel-1 \n",
    "The 2017 flood inundation maps are processed and produced by ICIMOD (Mr. Kabir Uddin), for example, [August composite inundation](http://rds.icimod.org/Home/DataDetail?metadataId=34492). Daily inundations are also generated for Jul-29, Aug-12, Aug-14, and Aug-24. Here we calculate inundated area (%) of each Union.</br>There was a resolution issue for August and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICIMOD's Flood Inundation Maps (Sentinel-1)\n",
    "# The monthly composite inundation maps (April, June, August) are exported as GeoTiff format \n",
    "# using \"QGIS>Export>Save as\"\n",
    "ref_path = './data/bgd_ppp_2017_30m_decuple.tif'\n",
    "in_path = './data/flood2017aug/Flood_Apr.tif'\n",
    "out_path = './data/flood_apr_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood_Jun.tif'\n",
    "out_path = './data/flood_jun_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood_Aug.tif'\n",
    "out_path = './data/flood_aug_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "# Daily inundation maps\n",
    "in_path = './data/flood2017aug/Flood data of Bangladesh on July 29, 2017/data/bd_flood_29_jul.img'\n",
    "out_path = './data/flood_jul29_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood data of Bangladesh on Aug 12, 2017/data/bd_flood_12_aug.img'\n",
    "out_path = './data/flood_aug12_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood data of Bangladesh on Aug 15, 2017/data/bd_flood_15_aug.img'\n",
    "out_path = './data/flood_aug15_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood data of Bangladesh on Aug 24, 2017/data/bd_flood_24_aug.img'\n",
    "out_path = './data/flood_aug24_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "\n",
    "# FFWC's Flood Inundation Map (Sentinel-1)\n",
    "in_path = './data/flood2017aug/FFWC+S1_FloodRasters_2017/S1-2017/S1_Mosaic_clp_2_BD.tif'\n",
    "out_path = './data/flood_aug_30m_ffwc.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint32,65536)\n",
    "\n",
    "\n",
    "# FFWC Flood Forecast (Inundation) Map issued at August-16, 2017\n",
    "in_path = './data/flood2017aug/FFWC+S1_FloodRasters_2017/2017.08.16/extract_floo1'\n",
    "out_path = './data/flood2017forecast_30m_aug16_ffwc_decuple.tif'\n",
    "##TODO: Update a function\n",
    "if False:\n",
    "    out_dtype = rasterio.uint32\n",
    "    out_nodata = 0\n",
    "    with rasterio.open(ref_path) as ref:\n",
    "            profile = ref.profile.copy()\n",
    "            profile.update(\n",
    "                dtype=out_dtype,\n",
    "                compress='lzw',\n",
    "                nodata=out_nodata)\n",
    "            with rasterio.open(in_path) as src:\n",
    "                sdata = src.read(1)\n",
    "                sdata[sdata < 0 ] = 0 \n",
    "                sdata = np.round(sdata*10).astype(out_dtype)          \n",
    "                with rasterio.open(out_path, 'w', **profile) as dst:\n",
    "                    reproject(\n",
    "                        source= sdata,\n",
    "                        destination=rasterio.band(dst, 1),\n",
    "                        src_transform=src.transform,\n",
    "                        src_crs=src.crs,\n",
    "                        dst_transform=dst.transform,\n",
    "                        dst_crs=dst.crs,\n",
    "                        resampling=Resampling.nearest)\n",
    "    print(\"%s is saved.\" % out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite inundation for 2017 August event\n",
    "Here, we make a composite inundation map which can represent overall inundated areas from the 2017 flood event.  \n",
    "The values of the composite maps represent: 1 (Perennial waterbodies), 2 (Flood inundation area), and 3 (Other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/bgd_inun_30m.tif is saved.\n"
     ]
    }
   ],
   "source": [
    "# List of inundation maps\n",
    "mon_path = ['./data/flood_apr_30m.tif', './data/flood_jun_30m.tif', './data/flood_aug_30m.tif']\n",
    "day_path = ['./data/flood_jul29_30m.tif', './data/flood_aug12_30m.tif', './data/flood_aug15_30m.tif', './data/flood_aug24_30m.tif']\n",
    "with rasterio.open(mon_path[0]) as src:\n",
    "    data = src.read(1)\n",
    "    inun = np.zeros(data.shape, rasterio.uint8)\n",
    "    profile = src.profile.copy()\n",
    "\n",
    "# Make a composite inundation\n",
    "# - Inundated area from daily maps\n",
    "for path in day_path:\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        inun[data == 1] = 2    \n",
    "# - Inundated area from monthly maps\n",
    "ONLYAUG = True\n",
    "if not ONLYAUG: \n",
    "    # Flood inundation from all months (April, June, August)\n",
    "    for path in mon_path:\n",
    "        with rasterio.open(path) as src:\n",
    "            data = src.read(1)\n",
    "            inun[data == 2] = 2\n",
    "else:\n",
    "    # Flood inundation from only August\n",
    "    with rasterio.open(mon_path[2]) as src:\n",
    "        data = src.read(1)\n",
    "        inun[data == 2] = 2\n",
    "# - Perennial water from monthly maps\n",
    "for path in mon_path:\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        inun[data == 1] = 1\n",
    "\n",
    "# Generate a new raster file\n",
    "out_fn = './data/bgd_inun_30m.tif'\n",
    "if not os.path.exists(out_fn):\n",
    "    with rasterio.open(out_fn, 'w+', **profile) as dst:\n",
    "        dst.write_band(1, inun)\n",
    "        print('%s is saved.' % out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25801248.1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Rasters\n",
    "Here, we clip global-scale rasters to Peruvian national boundary. Bangladesh UTM is {EPSG:32646}.\n",
    "1. DEM from HydroSHEDS\n",
    "2. 10-year flood inundation from GLOFRIS.\n",
    "3. Population from LandScan\n",
    "4. LandCover data from [European Space Agency (ESA)'s Climate Change Initiative (CCI)](https://cds.climate.copernicus.eu/cdsapp#!/dataset/satellite-land-cover?tab=overview)\n",
    "5. DistID (District ID of the district shapefile is converted to Raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aligned/raw/dem30s_bgd.tif is saved.\n",
      "./data/aligned/raw/dem30s_bgd_projected.tif is saved.\n",
      "./data/aligned/raw/inundation_00010.tif is saved.\n",
      "./data/aligned/raw/popu_admin_landscan17.tif is saved.\n",
      "./data/aligned/raw/lcss_aligned.tif is saved.\n",
      "./data/aligned/raw/uzid_30s.tif is saved\n"
     ]
    }
   ],
   "source": [
    "# Bangladesh national boundary\n",
    "shp_fn = './data/boundary_gadm/gadm36_BGD_0.shp'\n",
    "crs_bgd = 'EPSG:32646'\n",
    "\n",
    "# 1. Hydroshed DEM\n",
    "# - Crop raster with Peruvian national boundary\n",
    "rst_fn = '/Users/dlee/data/gis/hydrosheds/dem_void/as_dem_30s/as_dem_30s'\n",
    "out_fn = './data/aligned/raw/dem30s_bgd.tif'\n",
    "fhv.CropRasterShape(rst_fn, shp_fn, out_fn, all_touched=False)\n",
    "# - Reproject to UTM zone 17S (EPSG:32717)\n",
    "outpath = './data/aligned/raw/dem30s_bgd_projected.tif'\n",
    "fhv.ReprojectRaster(out_fn, outpath, new_crs=crs_bgd)\n",
    "\n",
    "# 2. GLOFRIS 10-year inundation\n",
    "rst_fn = '/Users/dlee/data/inundation/glofris/inun_dynRout_RP_00010.tif'\n",
    "out_fn = './data/aligned/raw/inundation_00010.tif'\n",
    "fhv.CropRasterShape(rst_fn, shp_fn, out_fn, all_touched=False)\n",
    "\n",
    "# 3. LandScan population\n",
    "rst_fn = '/Users/dlee/data/population/landscan/LandScan Global 2017/lspop2017'\n",
    "out_fn = './data/aligned/raw/popu_admin_landscan17.tif'\n",
    "fhv.CropRasterShape(rst_fn, shp_fn, out_fn, all_touched=False)\n",
    "# Total population of Bangladeh: 149,772,364 (BBS, 2011) or 159,670,593 (WorldBank, 2017)\n",
    "with rasterio.open(out_fn) as src: \n",
    "    popu = src.read().squeeze()\n",
    "    popu17 = np.sum(popu[popu != popu[0,0]])    # 158,455,362 (LandScan, 2017)\n",
    "    \n",
    "# 4. LandCover\n",
    "# Global LandCover layer is manually clipped using QGIS to the Bangladesh national boundary\n",
    "rst_fn = '/Users/dlee/data/landcover/C3S-LC-L4-LCCS-Map-300m-P1Y-2018-v2.1.1.tif'\n",
    "out_fn = './data/aligned/raw/lcss_aligned.tif'\n",
    "fhv.CropRasterShape(rst_fn, shp_fn, out_fn, all_touched=False)\n",
    "\n",
    "# 5. UpazilaID (converting administrative boundary polygon to raster)\n",
    "shp_fn = './data/boundary_gadm/gadm36_BGD_3.shp'\n",
    "rst_fn = './data/aligned/raw/dem30s_bgd.tif'\n",
    "out_fn = './data/aligned/raw/uzid_30s.tif'\n",
    "fhv.ConvertShapeToRaster(shp_fn, rst_fn, out_fn, 'CC_3', out_dtype=rasterio.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Codes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load code4 and code3\n",
    "fn = os.path.join('land', 'boundary_gadm', 'gadm4_code.tif')\n",
    "ds = gdal.Open(fn); dsCopy = ds\n",
    "code4 = ds.GetRasterBand(1).ReadAsArray()\n",
    "code3 = np.floor(code4/100)\n",
    "nocode = (code4 == code4[0,0])\n",
    "\n",
    "# Load census data\n",
    "cens = np.load('data_census.npy'); cens = cens.item()\n",
    "pop = cens['pop']\n",
    "\n",
    "\n",
    "#%% Load variables\n",
    "# Proximity to rivers (priv, 0-1)\n",
    "# (1km:1, 2km:0.5, 3km:0.2, 4+km:0)\n",
    "loc = './hydrology/river_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv = np.zeros(data.shape)\n",
    "priv[data != data[0,0]] = 2\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 5\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 10\n",
    "# - Scale to 0-1\n",
    "priv = fh.zeroToOne(priv)\n",
    "fh.evaluation('priv', priv, code4)\n",
    "\n",
    "# Proximity to cyclone shelters (pcsh, 0-1)\n",
    "# (1km:0, 2km:0.33, 3km:0.67, 4+km:1)\n",
    "loc = './hydrology/shelters_cyclone_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh = np.ones(data.shape)\n",
    "pcsh[data != data[0,0]] = 2/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 1/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "pcsh = fh.zeroToOne(pcsh)\n",
    "fh.evaluation('pcsh', pcsh, code4)\n",
    "\n",
    "# Number of cyclone shelters per Upazila capita (ncsh, 0-1)\n",
    "# (#shelters in Upazila / #pop in Upazila)\n",
    "fn = os.path.join(os.path.join('hydrology','shelters_cyclone',\n",
    "                               'cyclone_shelters_gadam4.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('cyclone_shelters_gadam4')\n",
    "#cshel_cc4 = df.Div_ID*10**6 + df.Dist_ID*10**4+df.Upz_ID*10**2+df.Un_ID\n",
    "cshel_cc3 = df.Div_ID*10**4 + df.Dist_ID*10**2+df.Upz_ID\n",
    "count = cshel_cc3.value_counts()\n",
    "ncsh = np.empty(code3.shape); ncsh[:] = 0\n",
    "for index, row in count.iteritems():\n",
    "    ncsh[code3 == index] = row/pop[pop[:,0] == index,1]\n",
    "# - Scale to 0-1\n",
    "ncsh = 1 - fh.zeroToOne(ncsh)\n",
    "fh.evaluation('ncsh', ncsh, code4)\n",
    "\n",
    "# Number of PHC and Hospitals\n",
    "fn = os.path.join(os.path.join('health','healthsites_lged', 'gadm4_join.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('gadm4_join')\n",
    "# - Number of Hospitals in Upazila (nhsp, 0-1)\n",
    "code3_hosp = np.floor(df[df.FType == 'Hospital'].CC_4/100)\n",
    "code3_hosp = code3_hosp.value_counts()\n",
    "nhsp = np.empty(code3.shape); nhsp[:] = 0\n",
    "for index, freq in code3_hosp.iteritems():\n",
    "    nhsp[code3 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nhsp = 1 - fh.zeroToOne(nhsp)\n",
    "fh.evaluation('nhsp', nhsp, code4)\n",
    "# - Number of PHC in Union (nphc, 0-1)\n",
    "code4_phc = df[df.FType == 'Family Welfare Centre'].CC_4\n",
    "code4_phc = code4_phc.value_counts()\n",
    "nphc = np.empty(code4.shape); nphc[:] = 0\n",
    "for index, freq in code4_phc.iteritems():\n",
    "    nphc[code4 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nphc = 1 - fh.zeroToOne(nphc)\n",
    "fh.evaluation('nphc', nphc, code4)\n",
    "\n",
    "# Slope (slop, 0-1)\n",
    "fn = os.path.join('land','slope_hydrosheds','slope_wgs84.tif')\n",
    "ds = gdal.Open(fn)\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('float32')   # (728, 559)\n",
    "slop = data[1:,:]                                            # (727, 559)\n",
    "slop[slop == slop[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "slop[code4 == code4[0,0]] = 0\n",
    "slop[slop != 0] = np.log(slop[slop != 0])\n",
    "slop[slop != 0] = fh.zeroToOne(slop[slop != 0])\n",
    "fh.evaluation('slop', slop, code4)\n",
    "\n",
    "# Climate: WorldClim\n",
    "loc = os.path.join('hydrology', 'clim_worldclim')\n",
    "prec = np.empty((727,559,4)); prec[:] = np.nan\n",
    "tavg = np.empty((727,559,4)); tavg[:] = np.nan\n",
    "wind = np.empty((727,559,4)); wind[:] = np.nan\n",
    "for i in range(4):\n",
    "    # - Precipitation (prec, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'prec_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        prec[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        prec[:,:,i] = temp[:-1,1:]\n",
    "    # - Temperature (tavg, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'tavg_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        tavg[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        tavg[:,:,i] = temp[:-1,1:]\n",
    "    # - Wind (wind, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'wind_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        wind[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        wind[:,:,i] = temp[:-1,1:]\n",
    "prec = np.mean(prec, axis=2); prec = fh.climInterpolate(prec, code4)\n",
    "tavg = np.mean(tavg, axis=2); tavg = fh.climInterpolate(tavg, code4)\n",
    "wind = np.mean(wind, axis=2); wind = fh.climInterpolate(wind, code4)\n",
    "# - Scale to 0-1\n",
    "prec[code4 != code4[0,0]] = fh.zeroToOne(np.log(prec[code4 != code4[0,0]]))\n",
    "tavg[code4 != code4[0,0]] = fh.zeroToOne(tavg[code4 != code4[0,0]])\n",
    "wind[code4 != code4[0,0]] = fh.zeroToOne(wind[code4 != code4[0,0]])\n",
    "fh.evaluation('prec', prec, code4)\n",
    "fh.evaluation('tavg', tavg, code4)\n",
    "fh.evaluation('wind', wind, code4)\n",
    "\n",
    "# Elevation (elev, 0 or 1)\n",
    "# *elev <= 5: 1, elev > 5: 0\n",
    "ds = gdal.Open(os.path.join('land','dem_hydrosheds','as_dem_30s_bgd.tif'))\n",
    "elev = ds.GetRasterBand(1).ReadAsArray().astype(float)\n",
    "elev[(elev >= 0) & (elev <= 5)] = 1\n",
    "elev[(elev > 5) | (elev < 0)] = 0\n",
    "fh.evaluation('elev', elev, code4)\n",
    "\n",
    "# Poverty from WorldPop dataset\n",
    "loc = os.path.join('socioecon', 'poverty_worldpop')\n",
    "# DHS wealth score (wlth, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2011wipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "wlth = np.empty(code4.shape); wlth[:] = np.nan  # (727,559)\n",
    "wlth[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (wlth == wlth[0,0]) | (np.isnan(wlth))\n",
    "wlth[~rdx] = 1 - fh.zeroToOne(wlth[~rdx])\n",
    "wlth[rdx] = 0\n",
    "fh.evaluation('wlth', wlth, code4)\n",
    "# Poverty (povt)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013ppipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "povt = np.empty(code4.shape); povt[:] = np.nan  # (727,559)\n",
    "povt[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (povt == povt[0,0]) | (np.isnan(povt))\n",
    "povt[~rdx] = fh.zeroToOne(povt[~rdx])\n",
    "povt[rdx] = 0\n",
    "fh.evaluation('povt', povt, code4)\n",
    "# Income (incm)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013incpov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "incm = np.empty(code4.shape); incm[:] = np.nan  # (727,559)\n",
    "incm[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (incm == incm[0,0]) | (np.isnan(incm))\n",
    "incm[~rdx] = 1 - fh.zeroToOne(incm[~rdx])\n",
    "incm[rdx] = 0\n",
    "fh.evaluation('incm', incm, code4)\n",
    "\n",
    "# GDP (gdp, 0-1)\n",
    "ds = gdal.Open(os.path.join('socioecon', 'gdp_kummu', 'gdp_ppp_2015_30s_bgd.tif'))\n",
    "gdp = ds.GetRasterBand(1).ReadAsArray()         # (727,559)\n",
    "rdx = np.isnan(gdp)\n",
    "# - Scale to 0-1\n",
    "gdp[~rdx] = 1 - fh.zeroToOne( np.log(gdp[~rdx]))\n",
    "gdp[rdx] = 0\n",
    "fh.evaluation('gdp', gdp, code4)\n",
    "\n",
    "# Flood prone area (fpro, 0 or 1)\n",
    "ds = gdal.Open(os.path.join('hydrology', 'flood prone area','fpro.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (727,559)\n",
    "fpro = np.zeros(temp.shape)\n",
    "fpro[temp == 0] = 1\n",
    "fh.evaluation('fpro', fpro, code4)\n",
    "\n",
    "# Flood depth (fdep, 0-1)\n",
    "loc = os.path.join('hydrology', 'inundation_glofris')\n",
    "ds = gdal.Open(os.path.join(loc, 'rp_00010.tif'))\n",
    "fdep = ds.GetRasterBand(1).ReadAsArray().astype('float')    # (727,559)\n",
    "fdep_copy = fdep.copy()\n",
    "# - Scale to 0.5-1\n",
    "fdep[fdep != 0] = fh.zeroToOne(fdep[fdep != 0])/2 + 0.5\n",
    "fh.evaluation('fdep', fdep, code4)\n",
    "\n",
    "# Accessibility to Healthcare facilities\n",
    "# *Travel time (minutes) is categoraized to 1-7\n",
    "# *Flooded areas are defined as the category of longest travel time\n",
    "loc = os.path.join('health', 'traveltime_lged')\n",
    "# - Travel time to PHC (tphc, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'family2000_clip.tif'))    # (728,559)\n",
    "tphc = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "tphc[np.isnan(tphc)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_family_rp00010_10p_clip.tif'))\n",
    "tphc_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "tphc_flood[np.isnan(tphc_flood)] = 0\n",
    "tphc_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to PHC (aphc, 0-1)\n",
    "aphc = tphc_flood - tphc\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'aphc.tif')\n",
    "temp = aphc.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Accessibility to Hospitals (thsp, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'hospital_clip.tif'))      # (728,559)\n",
    "thsp = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "thsp[np.isnan(thsp)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_hospital_rp00010_10p_clip.tif'))\n",
    "thsp_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "thsp_flood[np.isnan(thsp_flood)] = 0\n",
    "thsp_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to Hospitals (ahsp, 0-1)\n",
    "ahsp = thsp_flood - thsp\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'ahsp.tif')\n",
    "temp = ahsp.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Scale to 0-1\n",
    "tphc = fh.zeroToOne(fh.timeToCategory(tphc)); tphc[np.isnan(tphc)] = 1\n",
    "aphc = fh.zeroToOne(fh.timeToCategory(aphc)); aphc[np.isnan(aphc)] = 1\n",
    "thsp = fh.zeroToOne(fh.timeToCategory(thsp)); thsp[np.isnan(thsp)] = 1\n",
    "ahsp = fh.zeroToOne(fh.timeToCategory(ahsp)); ahsp[np.isnan(ahsp)] = 1\n",
    "fh.evaluation('tphc', tphc, code4)\n",
    "fh.evaluation('aphc', aphc, code4)\n",
    "fh.evaluation('thsp', thsp, code4)\n",
    "fh.evaluation('ahsp', ahsp, code4)\n",
    "\n",
    "# Save files\n",
    "fn = 'data_indices'\n",
    "data = {'priv':priv,'pcsh':pcsh,'ncsh':ncsh,'nhsp':nhsp,'nphc':nphc,'slop':slop,\n",
    "        'prec':prec,'tavg':tavg,'wind':wind,'elev':elev,'wlth':wlth,'povt':povt,\n",
    "        'incm':incm,'gdp':gdp,'fpro':fpro,'tphc':tphc,'aphc':aphc,'thsp':thsp,\n",
    "        'ahsp':ahsp, 'fdep':fdep}\n",
    "np.save(fn, data)\n",
    "print('{}.npy is saved..'.format(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aligned/raw/dem30s_bgd.tif is saved.\n",
      "./data/aligned/raw/dem30s_bgd_projected.tif is saved.\n",
      "./data/aligned/raw/inundation_00010.tif is saved.\n",
      "./data/aligned/raw/popu_admin_landscan17.tif is saved.\n",
      "./data/aligned/raw/lcss_aligned.tif is saved.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aligned/raw/uzid_30s.tif is saved\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment of Rasters\n",
    "Then, we align rasters in order to match their extent and resolution. This is done manually by QGIS > Raster > Align Rasters. The raster data includes:\n",
    "1. DEM: './data/alinged/raw/dem30_peru_Projected.tif' (reference raster; UTM zone 17S (EPSG:32717))\n",
    "2. Inundation: './data/aligned/raw/inundation_00010.tif'\n",
    "3. population: './data/aligned/raw/popu_admin_landscan17.tif'\n",
    "4. LandCover: './data/aligned/raw/landcover_peru.tif'\n",
    "5. DistID: './data/aligned/raw/distid_30s.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flood Inundation Barriers\n",
    "We polygonize the cells with flood depth over 1.0m.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aligned/polygonized/inundation_peru_1m.tif is saved.\n"
     ]
    }
   ],
   "source": [
    "# Read/Modify/Save the inundation raster\n",
    "in_ras = './data/aligned/inundation_peru.tif'\n",
    "out_ras = './data/aligned/polygonized/inundation_peru_1m.tif'\n",
    "with rasterio.open(in_ras, 'r') as src:\n",
    "    meta = src.meta.copy()\n",
    "    # Ignore cells with flood depth under 1.0 meter.\n",
    "    inun = src.read(1)\n",
    "    inun[inun < 10] = -32768\n",
    "    with rasterio.open(out_ras, 'w', **meta) as dest:\n",
    "        dest.write_band(1, inun)\n",
    "        print('%s is saved.' % out_ras)\n",
    "# The inundation raster is manually converted to shapefile (polygon) \n",
    "# by QGIS>Raster>Conversion>Polygonize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roads\n",
    "Roads data is obtained from [HOTOSM (OpenStreetMap) from Humnitarian Data Exchange](https://data.humdata.org/dataset/hotosm_per_roads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/road_osm.shp is saved.\n"
     ]
    }
   ],
   "source": [
    "filn_in = '/Users/dlee/data/per/roads/hotosm_per_roads_lines_shp/hotosm_per_roads_lines.shp'\n",
    "road = gpd.read_file(filn_in)\n",
    "# Select Primary, Secondary, and Tertiary roads\n",
    "road = road.loc[road['highway'].isin(['primary', 'secondary', 'tertiary'])]\n",
    "# Type and Class\n",
    "road = road.drop(['osm_id','name','surface','smoothness','width','lanes','oneway','bridge','layer','z_index'], axis=1)\n",
    "road_class = {1:'primary',2:'secondary',3:'tertiary'}\n",
    "road['class'] = 1\n",
    "road.loc[road.highway == 'secondary', 'class'] = 2\n",
    "road.loc[road.highway == 'tertiary', 'class'] = 3\n",
    "# Save\n",
    "if True:\n",
    "    filn_out = './data/road_osm.shp'\n",
    "    road.to_file(filn_out)\n",
    "    print('%s is saved.' % filn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rivers and Wetlands\n",
    "The hydrography data of Peru is obtained from [Humanitarian Data Exchange (HDX) (Instituto GeogrÃ¡fico Nacional - IGN)](https://data.humdata.org/dataset/hidrografia-de-peru).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education facilities\n",
    "Education facilities is obtained from [Ministry of Education > ESCALE](http://escale.minedu.gob.pe/mapas).\n",
    "https://wenr.wes.org/2015/04/education-in-peru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessibility Analysis\n",
    "The accessibility analysis is done by using [AccessMod 5](https://www.accessmod.org/) ([AccessMod 5 manual](https://doc-accessmod.unepgrid.ch/display/EN/AccessMod+5+user+manual)).\n",
    "- Accessibility to Health facilities\n",
    "- Accessibility to Education facilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load physical variables\n",
    "- Proximity to rivers\n",
    "     - We first merged all hydrography (polylines) into single shapefile (QGIS>Vector>Data Management Tools>Merge Vector Layers)\n",
    "     - Then we rasterize it (QGIS>Raster>Conversion>Rasterize)\n",
    "          - Picel Size: 924.473\n",
    "          - Extent: 463832.6140015202108771,7926421.1801450066268444, 1884747.2260907599702477,9995391.1878585517406464\n",
    "     - Proximity analysis (QGIS>Raster>Analysis>Proximity)\n",
    "- Slope\n",
    "    - We use DEM clipped with box\n",
    "    - Calculate slope using QGIS>Raster>Analysis>Slope\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical drivers names\n",
    "phys_name = [['PRRIV','neg','phys','Proximity to the rivers'],\n",
    "             ['SLOPE','pos','phys','Slope'],\n",
    "             ['ELEVATION','neg','phys','Low elevation'],\n",
    "             ['FDEPTH','pos','phys','Flood depth'],\n",
    "             ['TTHEALTH','pos','infra','Travel-time to health facilities']]\n",
    "phys_name = pd.DataFrame(phys_name, columns=['Name','Sign','Type','Description'])\n",
    "\n",
    "# Proximity to rivers (original unit: meters)\n",
    "# Scale distance: from 0km(1) to 3km(0)\n",
    "priv = rasterio.open('./data/proximity_river.tif').read(1)/1000\n",
    "priv[priv >= 3] = np.nan\n",
    "priv = 1-priv/3\n",
    "priv[np.isnan(priv)] = 0\n",
    "# fhv.GenerateRaster('./data/removable1.tif',meta.copy(),priv,new_dtype=rasterio.float32)\n",
    "\n",
    "# Slope (original unit: percent of slope)\n",
    "slope = rasterio.open('./data/slope.tif').read(1)\n",
    "slope[slope == -9999] = 0\n",
    "slope = slope/slope.max()\n",
    "\n",
    "# Elevation (original unit: meters)\n",
    "# Scale altitude: from -24m(1) to -5m(0)\n",
    "dem = rasterio.open('./data/dem_peru.tif').read(1).astype('float32')\n",
    "dem[(dem == -32768) | (dem > 5)] = np.nan\n",
    "dem = 1 - (dem + 24)/29\n",
    "dem[np.isnan(dem)] = 0\n",
    "\n",
    "# Flood depth (original unit : 10 cm)\n",
    "# Scale flood depth: from 0m(0) to 2m(1)\n",
    "fdepth = rasterio.open('./data/inundation_peru.tif').read(1).astype('float32')/10\n",
    "fdepth = fdepth/2\n",
    "fdepth[fdepth > 1] = 1\n",
    "\n",
    "# Accessibility to Health facilities\n",
    "ttheal = rasterio.open('./data/traveltime/health_noflood.tif').read(1).astype('float32')\n",
    "ttheal[ttheal < 0] = 5000\n",
    "ttheal = fhv.TTimeCategory(ttheal)\n",
    "ttheal = ttheal/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete dataset\n",
    "All variables are scaled. Here, we complete data preparation\n",
    "- Merge data table\n",
    "- Generate 2D Ndarray (col: valid cells, row: variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/variable.npy is saved..\n",
      "./data/variable_table.hdf is saved.\n"
     ]
    }
   ],
   "source": [
    "# Merge data table\n",
    "variable_name = pd.concat([data_name, phys_name]).reset_index(drop=True)\n",
    "# Load District ID\n",
    "with rasterio.open(os.path.join('data', 'distid_peru.tif')) as src:\n",
    "    did = src.read().squeeze()\n",
    "    meta = src.meta.copy()\n",
    "valid = did > 0\n",
    "valid_id = did[did >0]\n",
    "\n",
    "# Generate 2D Ndarray (col:valid cells, row:variables)\n",
    "# - District level data (census,risk,impact)\n",
    "ddata = np.zeros([valid.sum(), data_name.shape[0]]).astype('float32')\n",
    "for ic in range(data.shape[0]):\n",
    "    tid = data.iloc[ic].name\n",
    "    ddata[valid_id == tid, :] = data.iloc[ic].values\n",
    "# - Physical data\n",
    "pdata = np.vstack((priv[valid],slope[valid],dem[valid],fdepth[valid],ttheal[valid])).transpose()\n",
    "# - Merging\n",
    "variable = np.hstack((ddata,pdata))\n",
    "\n",
    "# Save variable data\n",
    "if True:\n",
    "    fn = './data/variable'\n",
    "    np.save(fn, variable)\n",
    "    print('{}.npy is saved..'.format(fn))\n",
    "    fn = './data/variable_table.hdf'\n",
    "    variable_name.to_hdf(fn, 'name')\n",
    "    print('%s is saved.' % fn)\n",
    "    fn = './data/variable_weight.xlsx'\n",
    "    variable_name.to_excel(fn)\n",
    "    print('%s is saved.' % fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archived scripts from here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribute district-level data to 1km x 1km raster format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a raster of district IDs\n",
    "with rasterio.open(os.path.join('data', 'distid_peru.tif')) as src:\n",
    "    did = src.read().squeeze()\n",
    "    meta = src.meta.copy()\n",
    "# fhv.censusToRaster('./census/page5.tif', meta, did, page5)\n",
    "# fhv.censusToRaster('./census/page5.tif', meta, did, page65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data control\n",
    "INEI data and 510 data has missing data at some districts. Here, we fill those values by taking the average value of their neighbors. This is done using the spatial weights matrix `w`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert np.isnan(data).sum().sum() == 0\n",
    "# import pysal as ps\n",
    "# w = ps.lib.weights.Queen.from_shapefile('./data/DISTRITOS.shp', idVariable='IDDIST')\n",
    "# w.transform = 'R'\n",
    "# data.loc[np.isnan(data['PAGE5'])]\n",
    "# ps.lib.weights.spatial_lag.lag_spatial(w, shp_fips.MHSEVAL_ALT)\n",
    "# dbf = ps.lib.io.open('./data/DISTRITOS.dbf')\n",
    "# iddist = dbf.by_col('IDDIST')\n",
    "# shp_fips = pd.DataFrame(dbf.by_col('IDDIST'), index=iddist)\n",
    "# shp_fips\n",
    "# print(w.n)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Automatic code for LandCover\n",
    "# from netCDF4 import Dataset\n",
    "# import rioxarray\n",
    "# import xarray\n",
    "# filn = '/Users/dlee/data/landcover/C3S-LC-L4-LCCS-Map-300m-P1Y-2018-v2.1.1.nc'\n",
    "# nc_fid = Dataset(filn, 'r')\n",
    "# # Use RioXarray\n",
    "# xds = xarray.open_dataset(filn)\n",
    "# xds.rio.set_crs(\"epsg:4326\")\n",
    "# xds[\"lccs_class\"].rio.to_raster('.\\test.tif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
